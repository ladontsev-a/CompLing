{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ca41e2",
   "metadata": {},
   "source": [
    "# Домашнее задание № 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0588a6",
   "metadata": {},
   "source": [
    "### Задание 1 Реализовать алгоритм Леска и проверить его на реальном датасете (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5283f",
   "metadata": {},
   "source": [
    "Ворднет можно использовать для дизамбигуации. Самый простой алгоритм дизамбигуации - алгоритм Леска. В нём нужное значение слова находится через пересечение слов контекста, в котором употреблено это слово, с определениями значений слова из ворднета. Значение с максимальным пересечением - нужное."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f082cd",
   "metadata": {},
   "source": [
    "Реализуйте его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54be341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853d1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_context(text, window=5):\n",
    "    word2context = []\n",
    "    text_tokenized = [word.lower() for word in word_tokenize(text)]\n",
    "    for i, word in enumerate(text_tokenized):\n",
    "        word2context.append((word, text_tokenized[max(0, i-window):i] + text_tokenized[i+1:i+window]))\n",
    "        \n",
    "    return word2context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "668e6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word, sentence):\n",
    "    bestsense = 0\n",
    "    maxoverlap = 0\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    for i, syns in enumerate(synsets):\n",
    "        definition = syns.definition().lower().split()\n",
    "        def_lemmatized = [lemmatizer.lemmatize(word) for word in definition]\n",
    "        \n",
    "        overlap = len(set(lemmatized) & set(def_lemmatized))\n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = i\n",
    "\n",
    "    return bestsense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4309c",
   "metadata": {},
   "source": [
    "**Проверьте насколько хорошо работает такой метод на датасете из семинара**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa7ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wsd = []\n",
    "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b8806",
   "metadata": {},
   "source": [
    "**Вам нужно для каждого многозначного слова (т.е. у него есть тэг в первом поле) с помощью алгоритма Леска предсказать нужный синсет и сравнить с правильным. Посчитайте процент правильных предсказаний (accuracy).**\n",
    "\n",
    "Если считается слишком долго, возьмите поменьше предложений (например, только тысячу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "762aa101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.37558198180173646\n"
     ]
    }
   ],
   "source": [
    "all_words = 0\n",
    "same_words = 0\n",
    "for sentence in corpus_wsd:\n",
    "    tokens = [word[2].lower() for word in sentence if len(word) == 3]\n",
    "    for i, word in enumerate(sentence):\n",
    "        if word[0]:\n",
    "            all_words += 1\n",
    "            context = tokens[max(0, i-5):i] + tokens[i+1:i+5]\n",
    "            meaning = lesk(word[1], context)\n",
    "            if wn.synsets(word[1])[meaning] == wn.lemma_from_key(word[0]).synset():\n",
    "                same_words += 1\n",
    "print('Accuracy score:', same_words/all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b45d4",
   "metadata": {},
   "source": [
    "### Задание 2* (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ef129",
   "metadata": {},
   "source": [
    "В семинаре для WSI на данных Диалога использовался только Fastext. Попробуйте заменить его на адаграм (обучите свою модель или используйте предобученную out.pkl или https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib), а также поэкспериментируйте с разными алгоритмами кластеризации и их параметрами (можно использовать только те алгоритмы, которые обучаются достаточно быстро)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e5ea3",
   "metadata": {},
   "source": [
    "Для каждого эксперимента рассчитайте ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1c17e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import adagram\n",
    "from razdel import tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, AffinityPropagation\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc527dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c2170d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24e8f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = adagram.VectorModel.load(\"out.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b019380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    words = [token.text.strip(punct) for token in list(tokenize(text))]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "51002422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_adagram(text, model, window, dim):\n",
    "    \n",
    "    \n",
    "    word2context = []\n",
    "    for i in range(len(text)-1):\n",
    "        left = max(0, i-window)\n",
    "        word = text[i]\n",
    "        left_context = text[left:i]\n",
    "        right_context = text[i+1:i+window]\n",
    "        context = left_context + right_context\n",
    "        word2context.append((word, context))\n",
    "\n",
    "    vectors = np.zeros((len(word2context), dim))\n",
    "    \n",
    "    for i,word in enumerate(word2context):\n",
    "        word, context = word\n",
    "        try:\n",
    "            sense = model.disambiguate(word, context).argmax()\n",
    "            v = model.sense_vector(word, sense)\n",
    "            vectors[i] = v \n",
    "\n",
    "        except (KeyError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51aae2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('word')[['word', 'context', 'gold_sense_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3ada1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize(model, window):\n",
    "    ARI = []\n",
    "\n",
    "    for key, _ in grouped_df:\n",
    "        texts = grouped_df.get_group(key)['context'].apply(normalize)\n",
    "        X = np.zeros((len(texts), 100))\n",
    "\n",
    "        for i, text in enumerate(texts):\n",
    "            text = [word for word in text if word != key]\n",
    "            X[i] = get_embedding_adagram(text, ada, window, 100)\n",
    "\n",
    "        model.fit(X)\n",
    "        labels = np.array(model.labels_) + 1\n",
    "        \n",
    "        ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "\n",
    "    print(np.mean(ARI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c31540",
   "metadata": {},
   "source": [
    "#### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f62e70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 2, max_iter=1000, n_init=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "52bf2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29596226533895065\n"
     ]
    }
   ],
   "source": [
    "clusterize(km, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee72040",
   "metadata": {},
   "source": [
    "#### SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9ffa4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpectralClustering(n_clusters=5, n_components = 4, n_neighbors = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "32508e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21284506922564658\n"
     ]
    }
   ],
   "source": [
    "clusterize(sc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707fc4",
   "metadata": {},
   "source": [
    "#### AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d0a63860",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6d4b2028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36738950708833995\n"
     ]
    }
   ],
   "source": [
    "clusterize(ac, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c05df9",
   "metadata": {},
   "source": [
    "#### AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ee9f638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AffinityPropagation(damping = 0.7, preference=-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "82fe4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\adagram\\model.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  z = np.log(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2441651885851499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFL\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clusterize(ap, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2985a",
   "metadata": {},
   "source": [
    "Вывод: лучший ARI показала модель AgglomerativeClustering с дефолтными параметрами и размером окна контекста 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf09b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
